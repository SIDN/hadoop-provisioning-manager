# The domainname used by the cluster serverr.
# It's very important that all the cluster hosts have a correct DNS config
# It's required that all the hosts use the same domainname
# e.g. host1.sidnlabs.nl, host2.sidnlabs.nl etc.
dns_domainname: sidnlabs.nl

# User used by ansible to deploy and control the services on the
# cluster nodes. This user must have sudo permission on all nodes.
provision_user: hadoop-mgr

# Cluster timezone, Kerberos is very time sensitive, make sure
# all cluster nodes have the same timezone/time set
timezone: Etc/UTC

# ntp server to synchronize time with
ntp_server: ntp.time.nl

# download location on ansible management node
# packaged are downloaded from remote repositories only to this 
# directory on the management node
download_root: /home/{{ provision_user }}/hadoop_downloads

# root dir for all component cfg directories
# for impala would be e.g.: {{ config_root }}/impala
config_root: /etc/sidn-hadoop

# file cache location on management node and servers
# packages and config may be cached in this directory on a cluster node
cache_root: /home/{{ provision_user }}/hadoop_cache

# Installation root directory for all hadoop related software packages
stack_root: /usr/local/hadoop

# Download url for packages built by sidn such as Apach Impala
# Some packages are only available as source code and have been compiled
# by sidn and made available at this repository url
repository_url: https://downloads.sidnlabs.nl/hadoop

# Component versions to deploy
version:
  postgresql: '15'
  python: '3.10'           # 3.10 is supported for RHEL 7.x
  java: '1.8.0'
  zookeeper: '3.8.0'
  hadoop: '3.3.4'
  spark: '3.3.2'
  spark_hadoop: '3'      # works for 3.2 and newer
  spark_metrics: '4.2.9'   # needed when hadoop < 3.2
  hive: '3.1.3'
  impala: '4.2.0'
  hue: '4.11.0'
  ranger: '2.2.0'
  solr: '8.11.2'
  livy: '0.8.0'
  airflow: '2.5.2'
  prometheus: '2.42.0'
  prometheus_node_exporter: 1.5.0
  grafana: '9.4.3'
  superset: '2.0'
  jupyterhub: '3.1.1'
  jupyterlab: '3.6.1'
  docker_registry_ui: 'latest'
  

# set path for python2 on the remote systems here
# python2 is only required for impala-shell  
python2_bin_path: '/usr/bin/python2'
# location where custom virtualenvs are created
python_venv_dir: '{{ stack_root }}/hadoop-venvs'
