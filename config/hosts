# Deploy dependencies on the manager host, this host is used to run ansible playbooks.
# only 1 host allowed in this group
[manager]
hadoop-dev4.example.nl

# Deploy simple webbased console with links to all the
# web interfaces for the cluster services
# only 1 host allowed in this group
[console]
hadoop-dev4.example.nl

# Deploy Zookeeper server on node in group: zookeeper
# Have at least 3 zookeepers and always and odd number of zookeepers
[zookeeper]
hadoop-dev4.example.nl
hadoop-dev5.example.nl
hadoop-dev6.example.nl

# The hadoop group contains the worker/data nodes
# Deploy 
# hadoop hdfs datanode
# yarn NodeManager
# spark 
[hadoop]
hadoop-dev4.example.nl
hadoop-dev5.example.nl
hadoop-dev6.example.nl

# The hdfs namenode is deployed on each
# host in group: hdfs_nn
# the hosts in this group may also be added to group: hadoop then they 
# also function as a datanode
# The ZKFC daemon (failover function) is also deployed to nodes in this group
# the first node will become the primary nn, the others are started as standby nn.
[hdfs_nn]
hadoop-dev4.example.nl
hadoop-dev5.example.nl

# HDFS journalnode function is deployed on hosts
# in group: hdfs_journalnode
# Have atleast 3 nodes and always and odd number of hosts
[hdfs_journalnode]
hadoop-dev4.example.nl
hadoop-dev5.example.nl
hadoop-dev6.example.nl

# deploy webhdfs/httpfs on host in group: hdfs_httpfs
# Only 1 host allowed in this group
[hdfs_httpfs]
hadoop-dev4.example.nl

# deploy Yarn Resource manager on host in group: yarn_resource_mgr
# Only 1 host allowed in this group
[yarn_resource_mgr]
hadoop-dev4.example.nl

# deploy Yarn Timeline server on host in group: yarn_timelineserver
# Only 1 host allowed in this group
[yarn_timelineserver]
hadoop-dev4.example.nl

# deploy Spark History server on host in group: spark_history
# Only 1 host allowed in this group
[spark_history]
hadoop-dev6.example.nl

# deploy Spark Thrift server on host in group: spark_thrift
# This can be used to execute SparkSQL from Hue
# Only 1 host allowed in this group
[spark_thrift]
hadoop-dev5.example.nl

# Install Hive Metastore on host
# in group: hive
# Only 1 host allowed in this group
[hive]
hadoop-dev5.example.nl

# Install Keberos KDC host in group: kerberos_kdc
# MIT Kerberos is used for centralized usermanagement (Authentication)
# Only 1 host allowed in this group
[kerberos_kdc]
hadoop-dev4.example.nl

# Deploy Ranger server on node in group: ranger
# Ranger is used for centralized HDFS/Impala permission management ( Authorization)
# Ranger will sync with local unix system users to get the users and groups
# Configure Impala/HDFS permissions in Ranger Admin UI
# Only 1 host allowed in this group
[ranger]
hadoop-dev6.example.nl

# Deploy SOLR server on node in group: solr
# SOLR is used for to save Ranger audit events
# Only 1 host allowed in this group
[solr]
hadoop-dev6.example.nl

# Install Postgresql database on host in group: database
# This database is used by hadoop/hue/ranger and more to
# persist their data. This can be an existing Postgresql database.
# If this an existing database then Postgresql will not be installed on the host
# Only 1 host allowed in this group
[database]
hadoop-dev2.example.nl

# deploy Impalad executor on nodes in group: impala
[impala]
hadoop-dev4.example.nl
hadoop-dev5.example.nl
hadoop-dev6.example.nl

# deploy Impala statestore server on node in group: impala_statestore
# Only 1 host allowed in this group
[impala_statestore]
hadoop-dev4.example.nl

# deploy Impala Catalog server on node in group: impala_catalog
# Only 1 host allowed in this group
[impala_catalog]
hadoop-dev4.example.nl

# deploy HAproxy for Impala HA, this deploys loadbalancer for the Impala executors
# Only 1 host allowed in this group
# do not deploy on host where already Impala executor is deployed.
# this causes port conflict, both listen on 25000 by default.
[impala_ha_proxy]
hadoop-dev4.example.nl

# deploy Hue server on node in group: hue
[hue]
hadoop-dev6.example.nl

# Livy is used to start a Yarn PySpark job from Hue
[livy]
hadoop-dev6.example.nl

# Functions as a gateway (client) to the cluster, contains all software and config
# Hadoop/Spark/Hive/Impala are deployed but no systemd services
# use a gateway node to interact with the cluster and run job from
# A gateway host MUST NOT be added to another group, except for the "Hue" group.
# otherwise the deployment might be incomplete
[gateway]
hadoop-dev2.example.nl

# Deploy Grafana/Prometheus monitoring server to node in group: monitor
# Use Grafana/Prometheus to monitor the state of the cluster services
[monitor]
hadoop-dev4.example.nl

[superset]
hadoop-dev2.example.nl

[jupyterhub]
hadoop-dev2.example.nl

[airflow]
hadoop-dev1.example.nl

[minio]
hadoop-dev1.example.nl

[minio_loadbalancer]
hadoop-dev2.example.nl