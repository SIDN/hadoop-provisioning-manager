# Start name nodes, there are multiple start modes available here:
# 1 Start unchanged cluster normal
# 2 Initialize and start a new hdfs cluster    
# 3 Upgrade and start an existing cluster

# The NEW file is generated during component deploy
- name: (New HDFS cluster) Check if HDFS needs to be initialized
  stat:
    path: "{{ hadoop_etc_dir }}/NEW"
  register: reg_new
  
# The UPGRADE file is generated during component deploy
- name: (New HDFS cluster) Check if HDFS needs to be upgraded
  stat:
    path: "{{ hadoop_etc_dir }}/UPGRADE"
  register: reg_upgrade

# initialize new HDFS fs
- name: Include Hadoop Initialization playbook
  include_tasks: ../roles/hadoop/tasks/hdfs-initialize.yml
  when: reg_new.stat.exists and not reg_upgrade.stat.exists
  
# check if the znode for hdfs HA exists in Zookeeper, must be at path: /hadoop-ha
# make sure to run this check on a zookeeper node.
- name: Check for HA state in ZooKeeper
  shell: >
      . {{ zookeeper_etc_dir }}/zk-env.sh;
      set +e;
      zkCli.sh stat /hadoop-ha
  register: zookeeper_ha_state_check
  ignore_errors: yes
  delegate_to: "{{ groups['zooKeeper'][0] }}"
  when: ('hdfs_primary_nn' in group_names)
  
- name: Show HA state in ZooKeeper
  debug: 
    msg: "HA state in ZooKeeper check {{ zookeeper_ha_state_check.stderr.find('Not found') == -1 }}"
  when: ('hdfs_primary_nn' in group_names)
  
# when reinstalling ZooKeeper there might not be ha state for an already
# installed hdfs component. need to reinitialize ZooKeeper
- name: Re-Initializing HA state in ZooKeeper
  shell: >
      . {{ hadoop_etc_dir }}/hadoop-env.sh;
      {{ stack_root }}/hadoop-latest/bin/hdfs zkfc -formatZK -nonInteractive
  become_user: "{{ hadoop_os_user.hdfs }}"
  become: yes
  when: ('hdfs_primary_nn' in group_names)
        and not (zookeeper_ha_state_check.stderr.find('Node does not exist') == -1)
  
# Upgrade existing HDFS fs
- name: Include Hadoop upgrade playbook
  include_tasks: ../roles/hadoop/tasks/hdfs-upgrade.yml
  when: reg_upgrade.stat.exists and not reg_new.stat.exists
  
# if not Initializing new cluster or upgrading an existing cluster 
# then do a normal start of the existing cluster.
- name: (Existing HDFS cluster) Start name node
  ansible.builtin.systemd:
      state: started
      daemon_reload: yes
      name: hdfs_namenode
  when: not reg_new.stat.exists and not reg_upgrade.stat.exists

# start failover Controller on name node
- name: (All HDFS cluster) Start ZK Failover Controller daemon
  ansible.builtin.systemd:
      state: started
      daemon_reload: yes
      name: hdfs_zkfc

# Cleanup
# Remove UPGRADE/NEW files after all NN have started
- name: (All HDFS cluster) Remove HDFS UPGRADE/NEW file (if present)
  ansible.builtin.file:
    path: "{{ hadoop_etc_dir }}/{{ item }}"
    state: absent
  loop:
    - UPGRADE
    - NEW

