# The NEW file is generated during component deploy
- name: (New HDFS cluster) Check if HDFS needs to be initialized
  stat:
    path: "{{ hadoop_etc_dir }}/NEW"
  register: reg_new
  
# The UPGRADE file is generated during component deploy
- name: (New HDFS cluster) Check if HDFS needs to be upgraded
  stat:
    path: "{{ hadoop_etc_dir }}/UPGRADE"
  register: reg_upgrade

- hosts: hdfs_journalnode
  remote_user: hadoop-mgr
  become: yes
  vars:
    service_name: hdfs_journalnode
  tasks:  
    - name: "Start service(s)"
      include_tasks: startup/tasks/generic-service.yml

# start primary hdfs namenode before standby      
- hosts: hdfs_nn[0]
  remote_user: hadoop-mgr
  vars_files:
    - "{{ prov_cfg_dir }}/vars/all.yml"
    - "{{ prov_cfg_dir }}/vars/hadoop_vars.yml"
    - "{{ prov_cfg_dir }}/vars/kerberos_vars.yml"
    - "{{ prov_cfg_dir }}/vars/zookeeper_vars.yml"
  become: yes
  tasks:
    - name: "Start primary name node"
      include_tasks: startup/tasks/hdfs_primary_nn.yml

# start standby nodes
- hosts: hdfs_nn[1:]
  remote_user: hadoop-mgr
  vars_files:
    - "{{ prov_cfg_dir }}/vars/all.yml"
    - "{{ prov_cfg_dir }}/vars/hadoop_vars.yml"
    - "{{ prov_cfg_dir }}/vars/kerberos_vars.yml"
    - "{{ prov_cfg_dir }}/vars/zookeeper_vars.yml"
  become: yes
  tasks:
    - name: "Start standby name nodes"
      include_tasks: startup/tasks/hdfs_standby_nn.yml
      
# create dirs, wait until Standby node(s) started
- hosts: hdfs_nn[0]
  remote_user: hadoop-mgr
  vars_files:
    - "{{ prov_cfg_dir }}/vars/all.yml"
    - "{{ prov_cfg_dir }}/vars/hadoop_vars.yml"
  become: yes
  tasks:  
    - name: (New HDFS cluster) Create HDFS root directories
      shell: >
          {{ stack_root }}/hadoop-latest/bin/init_hdfs_service.sh
      become_user: "{{ hadoop_os_user.hdfs }}"
      when: reg_new.stat.exists
      
# start data nodes
- hosts: hadoop
  remote_user: hadoop-mgr
  become: yes
  vars:
    service_name: hdfs_datanode
  tasks:
    - name: "Start service(s)"
      include_tasks: startup/tasks/generic-service.yml

- hosts: hdfs_httpfs
  remote_user: hadoop-mgr
  become: yes
  vars:
    service_name: hdfs_httpfs
  tasks:
    - name: "Start service(s)"
      include_tasks: startup/tasks/generic-service.yml      

# set datanode cpu resource limits
- hosts: hadoop
  remote_user: hadoop-mgr
  vars_files:
    - "{{ prov_cfg_dir }}/vars/all.yml"
    - "{{ prov_cfg_dir }}/vars/hadoop_vars.yml"
  become: yes     
  tasks:   
    - name: Set HDFS datanode cgroup cpu-shares
      shell: >
          systemctl set-property hdfs_datanode.service CPUShares={{ hadoop_cgroups.cpu_shares.hdfs_datanode }}
      when: ('hadoop' in groups and inventory_hostname in groups['hadoop'])

# Cleanup
# Remove UPGRADE/NEW files after all NN have started
- name: Remove HDFS UPGRADE/NEW file (if present)
  ansible.builtin.file:
    path: "{{ hadoop_etc_dir }}/{{ item }}"
    state: absent
  loop:
    - UPGRADE
    - NEW